#Pre-auths:

218 samples belonging to pre-auth, out of 438.
Bigram features (max_features=50).
Random Forest Best Parameters:  {'max_depth': 10, 'max_features': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 10}.
Tested on 132 test samples, 70 pre-auth, 62 not-pre-auth.
Train accuracy_rfc =  0.9738562091503268
Test accuracy_rfc =  0.9621212121212122



#KYC 

199 KYC Samples out of 374.
Unigram features (max_features=200).
Random Forest Best Parameters:  {'max_depth': 30, 'max_features': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 30}.
Train accuracy_RandomForest=  0.9922480620155039
Test accuracy_RandomForest=  0.9009009009009009

2nd approach was using TF-IDF feature creation method, but it wasn't optimal.


#Combined Model Classification (Ecard,kyc,pre_auth)

678 Samples, 100 features created using unigram Count Vectorizer.
Best Parameters:  {'max_depth': 20, 'max_features': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 10}
Best Accuracy: 91.57%
                  precision    recall  f1-score   support

       ecard       0.83      0.85      0.84        46
         kyc       0.85      0.86      0.85        65
    pre_auth       0.99      0.97      0.98        93

    accuracy                           0.91       204
   macro avg       0.89      0.89      0.89       204
weighted avg       0.91      0.91      0.91       204

Train accuracy_RandomForest=  0.9472573839662447
Test accuracy_RandomForest=  0.9068627450980392


#Combined Model Classification (Ecard, kyc, pa, ds, others), check distribution here 	content	
ds	232
ecard	158
kyc	199
others	224
pre_auth_form	321, 

30-70 test-train split was applied, unigram features.
Best Parameters:  {'max_depth': 30, 'max_features': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}
341 test samples, (pa_count,ecard_count,kyc_count,others_count,ds_count)=(91 53 67 63 67)




